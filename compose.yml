services:
  backend:
    &django_project
    build:
      context: .
      dockerfile: ./docker/backend/Dockerfile
    entrypoint: "uvicorn handwriting_recognition_service.asgi:application --host 0.0.0.0 --port 8000 --workers 4"
    restart: unless-stopped
    env_file:
      - ./docker/.env.prod
    volumes:
      - media_volume:/usr/src/app/media
      - models_volume:/usr/src/app/recognition_module/models/model
      - trains_volume:/usr/src/app/recognition_module/trains
    depends_on:
      db:
        condition: service_healthy
        restart: true
      redis: 
        condition: service_started
      rabbitmq: 
        condition: service_started
    develop:
      watch:
        - path: ./backend
          target: /usr/src/app
          action: sync+restart
    deploy:
      mode: replicated
      replicas: 1
      #endpoint_mode: dnsrr
      endpoint_mode: vip
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
        

  celery:
    <<: *django_project
    entrypoint: "celery -A handwriting_recognition_service worker --loglevel=info --concurrency 2 -E -P threads"
    depends_on:
      backend:
        condition: service_started
    deploy:
      mode: replicated
      replicas: 1
      #endpoint_mode: dnsrr
      endpoint_mode: vip
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]

  nginx:
    image: nginx
    restart: unless-stopped #always
    ports:
      - 80:80
    volumes:
      - ./docker/nginx/default.conf:/etc/nginx/conf.d/default.conf
      - ./frontend/dist:/usr/share/nginx/html
      - media_volume:/usr/src/app/media
    depends_on:
      - backend

  #adminer:
  #  image: adminer
  #  restart: always
  #  ports:
  #    - 8080:8080

  db:
    image: postgres
    volumes:
      - postgres_data:/var/lib/postgresql/data/
    env_file:
      - ./docker/.env.prod
    healthcheck:
      test: ["CMD-SHELL", "pg_isready", "-U", "postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G

  redis:
    image: "redis:alpine"
    depends_on:
      db:
        condition: service_healthy
    volumes: 
      - redis_volume:/data

  rabbitmq:
    image: rabbitmq:3.10.7-management
    hostname: rabbitmq
    restart: always
    env_file:
      - ./docker/.env.prod
    volumes:
      - rabbitmq_volume:/var/lib/rabbitmq

  grafana:
    image: grafana/grafana
    volumes:
      - grafana_volume:/var/lib/grafana
      - ./docker/grafana/grafana.ini:/etc/grafana/grafana.ini
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    restart: unless-stopped
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_volume:/prometheus
    command: 
      - '--config.file=/etc/prometheus/prometheus.yml'
    depends_on:
      - backend 

  cadvisor:
    image: gcr.io/cadvisor/cadvisor
    restart: unless-stopped
    devices:
      - "/dev/kmsg:/dev/kmsg"
    command:
      - '--enable_load_reader=true'
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /var/run/docker.sock:/var/run/docker.sock:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro

volumes:
  postgres_data:
  media_volume:
  models_volume:
  trains_volume:
  rabbitmq_volume:
  redis_volume:
    driver: local
  grafana_volume:
  prometheus_volume:
